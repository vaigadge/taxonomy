created_by: Abhi-B
domain: ibm rebooks
seed_examples:
- answer: |
    chat, download, generate, init, list, serve, test and train
  question: |
    What sub-commands does `lab` has?
- answer: |
    `lab train` works locally for MacBook with M chips and there is a notebook can be used on the cloud
  question: |
    What options are there for training using InstructLab CLI?
- answer: |
    run `lab download`
  question: |
    How to download the model using the InstructLab CLI
- answer: |
    run `lab init`
  question: |
    how to initialize the workspace using the InstructLab CLI
task_description: 'How to the `lab` command for the InstructLab CLI'
document: |
  # InstructLab ü•º (`lab`)

  ## ‚ùì What is `lab`

  `lab` is a Command-Line Interface (CLI) tool that allows you to:

  1. Download a pre-trained LLM (Large Laungage Model).
  2. Chat with the LLM.

  To add new knowledge and skills to the pre-trained LLM you have to add new information to the companion [taxonomy](https://github.com/instruct-lab/taxonomy.git) repository.
  After that is done, you can:

  1. Use `lab` to generate new synthetic training data based on the changes in your local `taxonomy` repository.
  2. Re-train the LLM with the new training data.
  3. Chat with the re-trained LLM to see the results.

  ## üìã Requirements

  - **üçé Apple M1/M2/M3 Mac or üêß Linux system** (tested on Fedora). We anticipate support for more operating systems in the future.
  - The GNU C++ compiler
  - üêç Python 3.9 or later, including the development headers.
  - Approximately 10GB of free disk space to get through the `lab generate` step.  Approximately 60GB of free disk space to fully run the entire process locally on Apple hardware.

  On Fedora Linux this means installing:
  ```
  $ sudo yum install g++ python3 python3-devel
  ```

  ## ‚úÖ Getting started 
  ### üß∞ Installing `lab`

  To start, create a new directory called `instruct-lab` to store the files that the `lab` CLI needs when it runs.

  ```
  mkdir instruct-lab
  cd instruct-lab
  python3 -m venv venv
  source venv/bin/activate
  pip install git+ssh://git@github.com/instruct-lab/cli.git@stable
  ```
  > **NOTE**: ‚è≥ `pip install` may take some time, depending on your internet connection.

  **Every** `lab` command needs to be run from within your Python virtual environment. To enter the Python environment, run the following command: 

  ```
  source venv/bin/activate
  ```

  ### üèóÔ∏è Initialize `lab`

  ```
  lab init
  ```
  Initializing `lab` will: 
  1. Add a new, default `config.yaml` file. 
  2. Clone the `git@github.com:instruct-lab/taxonomy.git` repository into the current directory.

  ```
  (venv) $ lab init
  Welcome to InstructLab CLI. This guide will help you to setup your environment.
  Please provide the following values to initiate the environment:
  Path to taxonomy repo [taxonomy]: <ENTER>
  `taxonomy` seems to not exists or is empty. Should I clone git@github.com:instruct-lab/taxonomy.git for you? [y/N]: y
  Cloning git@github.com:instruct-lab/taxonomy.git...
  Generating `config.yaml` in the current directory...
  Initialization completed successfully, you're ready to start using `lab`. Enjoy!
  ```

  `lab` will use the default configuration file unless otherwise specified.
  You can override this behavior for any `lab` command with the `--config` parameter.

  ### üì• Download the model

  ```
  lab download
  ```

  `lab download` will download a pre-trained model from HuggingFace and store it in a `models` directory:

  ```
  (venv) $ lab download
  Downloading model from ibm/merlinite-7b-GGUF@main to models...
  (venv) $ ls models
  merlinite-7b-Q4_K_M.gguf
  ```

  > **NOTE** ‚è≥ This command can take few minutes or immediately depending on your internet connection or model is cached.

  ### üç¥ Serving the model

  ```
  lab serve
  ```
  
  ### üì£ Chat with the model (Optional)

  Because you're serving the model in one terminal window, you likely have to create a new window and re-activate your Python virtual environment to run `lab chat`:
  ```
  source venv/bin/activate
  lab chat
  ```

  ## üíª Creating new knowledge and training the model
  ### üéÅ Contribute knowledge or compositional skills

  Locally contribute new knowledge or compositional skills to your local [taxonomy](https://github.com/instruct-lab/taxonomy.git) repository.

  Detailed contribution instructions can be found on the [taxonomy github](https://github.com/instruct-lab/taxonomy/blob/main/README.md).

  ### üìú List your new knowledge

  ```
  lab list
  ```

  To ensure `lab` is registering your new knowledge, you can run `lab list`.

  The following is the expected result after adding the new compositional skill foo-lang:
  ```
  (venv) $ lab list
  compositional_skills/writing/freeform/foo-lang/foo-lang.yaml
  ```

  ### üöÄ Generate a synthetic dataset

  ```
  lab generate
  ```

  The next step is to generate a synthetic dataset based on your newly added knowledge set in the [taxonomy](https://github.com/instruct-lab/taxonomy.git) repository:

  ```
  (venv) $ lab generate
  INFO 2024-02-29 19:09:48,804 lab.py:250 Generating model 'ggml-merlinite-7b-0302-Q4_K_M' using 10 cpus,
  taxonomy: '/home/username/instruct-lab/taxonomy' and seed 'seed_tasks.json'

  0%|##########| 0/100 Cannot find prompt.txt. Using default prompt.
  98%|##########| 98/100 INFO 2024-02-29 20:49:27,582 generate_data.py:428 Generation took 5978.78s
  ```

  The synthetic data set will be three files in the newly created `generated` directory that are named like: `generated*.json`, `test*.jsonl`, and `train*.jsonl`:
  ```
  (venv) $ ls generated/
  'generated_ggml-malachite-7b-0226-Q4_K_M_2024-02-29T19 09 48.json'   'train_ggml-malachite-7b-0226-Q4_K_M_2024-02-29T19 09 48.jsonl'
  'test_ggml-malachite-7b-0226-Q4_K_M_2024-02-29T19 09 48.jsonl'
  ```

  > **NOTE:** ‚è≥ This can take over **1 hour+** to complete depending on your computing resources.

  ### üë©‚Äçüè´ Train the model

  There are currently two options to train the model on your synthetic data-enhanced dataset.

  #### Training the model locally on an M-series Mac:

  ```
  lab train
  lab convert
  ```

  #### Training the model in Colab:

  Follow the instructions in [Training](./notebooks/README.md).

  > **NOTE:** ‚è≥ This takes about **0.5-2.5 hours** to complete in the free tier of Google Colab.

  After that's done, download the newly trained model from Google Colab and put it in the `models` directory created by the `lab download` command.

  ### üç¥ Serve the newly trained model

  Stop the server you have running via `Ctrl+C` in the terminal it is running in.

  Serve the newly trained model locally using `lab serve` with the `--model` argument to specify your new model:

  ```
  lab serve --model-path <New model name>
  ```

  ### üì£ Chat with the new model (not optional this time)

  Try the fine-tuned model out live using the chat interface, and see if the results are better than the untrained version of the model with chat.

  ```
  lab chat -m <New model name>
  ```
  ## üéÅ Submit your new knowledge

  Of course the final step is, if you've improved the model, to open up a a pull-request in the [taxonomy repository](https://github.com/instruct-lab/taxonomy).

  ## üì¨ Contributing

  Check out our [contributing](CONTRIBUTING/CONTRIBUTING.md) guide to learn how to contribute to the InstructLab CLI.